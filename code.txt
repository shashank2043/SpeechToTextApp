// Speech-to-Text Transcription App using MERN Stack, MongoDB, and Deepgram API

// Backend: Express.js Server Setup
const express = require('express');
const multer = require('multer');
const cors = require('cors');
const mongoose = require('mongoose');
const { Deepgram } = require('@deepgram/sdk');
require('dotenv').config();

const app = express();
const PORT = process.env.PORT || 5000;
const deepgram = new Deepgram(process.env.DEEPGRAM_API_KEY);

app.use(cors());
app.use(express.json());

mongoose.connect(process.env.MONGO_URI, {
  useNewUrlParser: true,
  useUnifiedTopology: true,
});

const transcriptionSchema = new mongoose.Schema({
  audioUrl: String,
  text: String,
  createdAt: { type: Date, default: Date.now },
});
const Transcription = mongoose.model('Transcription', transcriptionSchema);

const storage = multer.memoryStorage();
const upload = multer({ storage });

app.post('/upload', upload.single('audio'), async (req, res) => {
  try {
    const buffer = req.file.buffer;
    const response = await deepgram.transcription.preRecorded({ buffer }, { punctuate: true });
    const text = response.results.channels[0].alternatives[0].transcript;
    
    const newTranscription = new Transcription({ text });
    await newTranscription.save();
    res.json({ text });
  } catch (error) {
    res.status(500).json({ error: error.message });
  }
});

app.get('/transcriptions', async (req, res) => {
  const transcriptions = await Transcription.find().sort({ createdAt: -1 });
  res.json(transcriptions);
});

app.listen(PORT, () => console.log(`Server running on port ${PORT}`));

// Frontend: React Setup with Vite
import React, { useState, useEffect } from 'react';
import axios from 'axios';
import './App.css';

function App() {
  const [audio, setAudio] = useState(null);
  const [transcriptions, setTranscriptions] = useState([]);
  const [loading, setLoading] = useState(false);

  useEffect(() => {
    axios.get('http://localhost:5000/transcriptions').then((res) => setTranscriptions(res.data));
  }, []);

  const handleFileChange = (e) => {
    setAudio(e.target.files[0]);
  };

  const handleUpload = async () => {
    if (!audio) return;
    setLoading(true);
    const formData = new FormData();
    formData.append('audio', audio);
    try {
      const res = await axios.post('http://localhost:5000/upload', formData);
      setTranscriptions([res.data, ...transcriptions]);
    } catch (error) {
      console.error(error);
    }
    setLoading(false);
  };

  return (
    <div className="container mx-auto p-4">
      <h1 className="text-2xl font-bold mb-4">Speech-to-Text Transcription</h1>
      <input type="file" onChange={handleFileChange} className="mb-2" />
      <button onClick={handleUpload} className="bg-blue-500 text-white p-2 rounded">
        {loading ? 'Transcribing...' : 'Upload & Transcribe'}
      </button>
      <div className="mt-4">
        <h2 className="text-xl font-semibold">Transcriptions</h2>
        <ul>
          {transcriptions.map((t, index) => (
            <li key={index} className="border p-2 mt-2">{t.text}</li>
          ))}
        </ul>
      </div>
    </div>
  );
}

export default App;

// Ensure you have Tailwind CSS configured in your project
